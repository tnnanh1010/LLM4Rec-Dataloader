{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb2bDxXnL4Ot",
        "outputId": "a5cf2e33-b982-4137-ce69-b654c3071002"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E7i79ErILbl8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import random\n",
        "import logging\n",
        "import os\n",
        "import torch.optim as optim\n",
        "import torch.distributed as dist\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "WxUXYhf2MjaM"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Optional\n",
        "\n",
        "@dataclass\n",
        "class Args:\n",
        "    nGPU: int = 1\n",
        "    seed: int = 0\n",
        "    prepare: bool = True\n",
        "    mode: str = \"train\"\n",
        "    train_data_dir: str = \"/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_train\"\n",
        "    test_data_dir: str = \"/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_dev\"\n",
        "    train_abstract_dir: str = '/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json'\n",
        "    # \"/content/drive/MyDrive/Colab Notebooks/NewsRecommendation/data/train_gen_abs.json\"\n",
        "    test_abstract_dir: str = '/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json'\n",
        "    # \"/content/drive/MyDrive/Colab Notebooks/NewsRecommendation/data/Dev_gen_abs.json\"\n",
        "    model_dir: str = '/content/model'\n",
        "    batch_size: int = 32\n",
        "    npratio: int = 4\n",
        "    enable_gpu: bool = False\n",
        "    filter_num: int = 3\n",
        "    log_steps: int = 100\n",
        "    epochs: int = 5\n",
        "    lr: float = 0.0003\n",
        "    num_words_title: int = 20\n",
        "    num_words_abstract: int = 50\n",
        "    user_log_length: int = 50\n",
        "    word_embedding_dim: int = 300\n",
        "    glove_embedding_path: str = '/home/vinmike/Downloads/glove.840B.300d.txt'\n",
        "    freeze_embedding: bool = False\n",
        "    news_dim: int = 300\n",
        "    news_query_vector_dim: int = 200\n",
        "    user_query_vector_dim: int = 200\n",
        "    num_attention_heads: int = 15\n",
        "    user_log_mask: bool = False\n",
        "    drop_rate: float = 0.2\n",
        "    save_steps: int = 10000\n",
        "    start_epoch: int = 0\n",
        "    load_ckpt_name: Optional[str] = None\n",
        "    use_category: bool = True\n",
        "    use_subcategory: bool = True\n",
        "    use_abstract: bool = True\n",
        "    use_custom_abstract: bool = True\n",
        "    category_emb_dim: int = 100\n",
        "\n",
        "def parse_args():\n",
        "  return Args()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_SLKbAZpKFK"
      },
      "source": [
        "**Dataset.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pqMrlk2u-Hiv"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import IterableDataset, Dataset\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "class DatasetTrain(IterableDataset):\n",
        "    def __init__(self, filename, news_index, news_combined, args):\n",
        "        super(DatasetTrain).__init__()\n",
        "        self.filename = filename\n",
        "        self.news_index = news_index\n",
        "        self.news_combined = news_combined\n",
        "        self.args = args\n",
        "\n",
        "    def trans_to_nindex(self, nids):\n",
        "        return [self.news_index[i] if i in self.news_index else 0 for i in nids]\n",
        "\n",
        "    def pad_to_fix_len(self, x, fix_length, padding_front=True, padding_value=0):\n",
        "        if padding_front:\n",
        "            pad_x = [padding_value] * (fix_length - len(x)) + x[-fix_length:]\n",
        "            mask = [0] * (fix_length - len(x)) + [1] * min(fix_length, len(x))\n",
        "        else:\n",
        "            pad_x = x[-fix_length:] + [padding_value] * (fix_length - len(x))\n",
        "            mask = [1] * min(fix_length, len(x)) + [0] * (fix_length - len(x))\n",
        "        return pad_x, np.array(mask, dtype='float32')\n",
        "\n",
        "    def line_mapper(self, line):\n",
        "        line = line.strip().split('\\t')\n",
        "        click_docs = line[3].split()\n",
        "        sess_pos = line[4].split()\n",
        "        sess_neg = line[5].split()\n",
        "\n",
        "        click_docs, log_mask = self.pad_to_fix_len(self.trans_to_nindex(click_docs), self.args.user_log_length)\n",
        "        user_feature = self.news_combined[click_docs]\n",
        "\n",
        "        pos = self.trans_to_nindex(sess_pos)\n",
        "        neg = self.trans_to_nindex(sess_neg)\n",
        "\n",
        "        label = random.randint(0, self.args.npratio)\n",
        "        sample_news = neg[:label] + pos + neg[label:]\n",
        "        sample_news, log_mask = self.pad_to_fix_len(sample_news, self.args.user_log_length)\n",
        "\n",
        "        news_feature = self.news_combined[sample_news]\n",
        "        \n",
        "        return user_feature, news_feature, label\n",
        "\n",
        "    def __iter__(self):\n",
        "        file_iter = open(self.filename)\n",
        "        return map(self.line_mapper, file_iter)\n",
        "\n",
        "\n",
        "\n",
        "class DatasetTest(DatasetTrain):\n",
        "    def __init__(self, filename, news_index, news_scoring, args):\n",
        "        super(DatasetTrain).__init__()\n",
        "        self.filename = filename\n",
        "        self.news_index = news_index\n",
        "        self.news_scoring = news_scoring\n",
        "        self.args = args\n",
        "\n",
        "    def line_mapper(self, line):\n",
        "        line = line.strip().split('\\t')\n",
        "        click_docs = line[3].split()\n",
        "        click_docs, log_mask = self.pad_to_fix_len(self.trans_to_nindex(click_docs), self.args.user_log_length)\n",
        "        user_feature = self.news_scoring[click_docs]\n",
        "\n",
        "        candidate_news = self.trans_to_nindex([i.split('-')[0] for i in line[4].split()])\n",
        "        labels = np.array([int(i.split('-')[1]) for i in line[4].split()])\n",
        "        news_feature = self.news_scoring[candidate_news]\n",
        "\n",
        "        return user_feature, log_mask, news_feature, labels\n",
        "\n",
        "    def __iter__(self):\n",
        "        file_iter = open(self.filename)\n",
        "        return map(self.line_mapper, file_iter)\n",
        "\n",
        "\n",
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1IjisEE-LHb"
      },
      "source": [
        "**Metric.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ppd8qdG1-Nr3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def dcg_score(y_true, y_score, k=10):\n",
        "    order = np.argsort(y_score)[::-1]\n",
        "    y_true = np.take(y_true, order[:k])\n",
        "    gains = 2**y_true - 1\n",
        "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
        "    return np.sum(gains / discounts)\n",
        "\n",
        "\n",
        "def ndcg_score(y_true, y_score, k=10):\n",
        "    best = dcg_score(y_true, y_true, k)\n",
        "    actual = dcg_score(y_true, y_score, k)\n",
        "    return actual / best\n",
        "\n",
        "\n",
        "def mrr_score(y_true, y_score):\n",
        "    order = np.argsort(y_score)[::-1]\n",
        "    y_true = np.take(y_true, order)\n",
        "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
        "    return np.sum(rr_score) / np.sum(y_true)\n",
        "\n",
        "\n",
        "def ctr_score(y_true, y_score, k=1):\n",
        "    order = np.argsort(y_score)[::-1]\n",
        "    y_true = np.take(y_true, order[:k])\n",
        "    return np.mean(y_true)\n",
        "\n",
        "def acc(y_true, y_hat):\n",
        "    y_hat = torch.argmax(y_hat, dim=-1)\n",
        "    tot = y_true.shape[0]\n",
        "    hit = torch.sum(y_true == y_hat)\n",
        "    return hit.data.float() * 1.0 / tot\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1ZeoY8x-5Ds"
      },
      "source": [
        "**Ultis.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Dfr-ri4E-s3M"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import argparse\n",
        "import sys\n",
        "\n",
        "def setuplogger():\n",
        "    root = logging.getLogger()\n",
        "    root.setLevel(logging.INFO)\n",
        "    handler = logging.StreamHandler(sys.stdout)\n",
        "    handler.setLevel(logging.INFO)\n",
        "    formatter = logging.Formatter(\"[%(levelname)s %(asctime)s] %(message)s\")\n",
        "    handler.setFormatter(formatter)\n",
        "    root.addHandler(handler)\n",
        "\n",
        "\n",
        "def dump_args(args):\n",
        "    for arg in dir(args):\n",
        "        if not arg.startswith(\"_\"):\n",
        "            logging.info(f\"args[{arg}]={getattr(args, arg)}\")\n",
        "\n",
        "def load_matrix(embedding_file_path, word_dict, word_embedding_dim):\n",
        "    embedding_matrix = np.zeros(shape=(len(word_dict) + 1, word_embedding_dim))\n",
        "    have_word = []\n",
        "    if embedding_file_path is not None:\n",
        "        with open(embedding_file_path, 'rb') as f:\n",
        "            while True:\n",
        "                line = f.readline()\n",
        "                if len(line) == 0:\n",
        "                    break\n",
        "                line = line.split()\n",
        "                word = line[0].decode()\n",
        "                if word in word_dict:\n",
        "                    index = word_dict[word]\n",
        "                    tp = [float(x) for x in line[1:]]\n",
        "                    embedding_matrix[index] = np.array(tp)\n",
        "                    have_word.append(word)\n",
        "    return embedding_matrix, have_word\n",
        "\n",
        "\n",
        "def get_checkpoint(directory, ckpt_name):\n",
        "    ckpt_path = os.path.join(directory, ckpt_name)\n",
        "    if os.path.exists(ckpt_path):\n",
        "        return ckpt_path\n",
        "    else:\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqNlsklUAi48"
      },
      "source": [
        "**preprocess.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_Ja_pvD0AYwg"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "import json\n",
        "\n",
        "\n",
        "def update_dict(dict, key, value=None):\n",
        "    if key not in dict:\n",
        "        if value is None:\n",
        "            dict[key] = len(dict) + 1\n",
        "        else:\n",
        "            dict[key] = value\n",
        "\n",
        "\n",
        "def read_custom_abstract(news_file, custom_abstract_dict):\n",
        "    news = {}\n",
        "    news_index = {}\n",
        "    category_dict = {}\n",
        "    subcategory_dict = {}\n",
        "    word_cnt = {}\n",
        "\n",
        "    with open(news_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            splited = line.strip('\\n').split('\\t')\n",
        "            doc_id, category, subcategory, title, abstract, url, entity_title, entity_abstract = splited\n",
        "            if doc_id in custom_abstract_dict:\n",
        "                abstract = custom_abstract_dict[doc_id]\n",
        "            news[doc_id] = [title.split(' '), category, subcategory, abstract.split(' ')]\n",
        "            news_index[doc_id] = len(news_index) + 1\n",
        "            for word in title.split(' '):\n",
        "                if word not in word_cnt:\n",
        "                    word_cnt[word] = 0\n",
        "                word_cnt[word] += 1\n",
        "            for word in abstract.split(' '):\n",
        "                if word not in word_cnt:\n",
        "                    word_cnt[word] = 0\n",
        "                word_cnt[word] += 1\n",
        "            if category not in category_dict:\n",
        "                category_dict[category] = len(category_dict) + 1\n",
        "            if subcategory not in subcategory_dict:\n",
        "                subcategory_dict[subcategory] = len(subcategory_dict) + 1\n",
        "\n",
        "    return news, news_index, category_dict, subcategory_dict, word_cnt\n",
        "\n",
        "def read_news(news_path, abstract_path, args, mode='train'):\n",
        "    news = {}\n",
        "    category_dict = {}\n",
        "    subcategory_dict = {}\n",
        "    news_index = {}\n",
        "    word_cnt = Counter()\n",
        "    if args.use_custom_abstract:\n",
        "      with open(abstract_path, 'r') as f:\n",
        "          abs = json.load(f)\n",
        "    with open(news_path, 'r', encoding='utf-8') as f:\n",
        "        for line in tqdm(f):\n",
        "            splited = line.strip('\\n').split('\\t')\n",
        "            doc_id, category, subcategory, title, abstract, url, _, _ = splited\n",
        "            update_dict(news_index, doc_id)\n",
        "\n",
        "            title = title.lower()\n",
        "            title = word_tokenize(title, language='english', preserve_line=True)\n",
        "\n",
        "            update_dict(news, doc_id, [title, category, subcategory, abs[doc_id] if doc_id in abs else abstract])\n",
        "            if mode == 'train':\n",
        "                if args.use_category:\n",
        "                    update_dict(category_dict, category)\n",
        "                if args.use_subcategory:\n",
        "                    update_dict(subcategory_dict, subcategory)\n",
        "                word_cnt.update(title)\n",
        "\n",
        "    if mode == 'train':\n",
        "        word = [k for k, v in word_cnt.items() if v > args.filter_num]\n",
        "        word_dict = {k: v for k, v in zip(word, range(1, len(word) + 1))}\n",
        "        return news, news_index, category_dict, subcategory_dict, word_dict\n",
        "    elif mode == 'test':\n",
        "        return news, news_index\n",
        "    else:\n",
        "        assert False, 'Wrong mode!'\n",
        "\n",
        "\n",
        "def get_doc_input(news, news_index, category_dict, subcategory_dict, word_dict, args):\n",
        "    news_num = len(news) + 1\n",
        "    news_title = np.zeros((news_num, args.num_words_title), dtype='int32')\n",
        "    news_category = np.zeros((news_num, 1), dtype='int32') if args.use_category else None\n",
        "    news_subcategory = np.zeros((news_num, 1), dtype='int32') if args.use_subcategory else None\n",
        "    news_abstract = np.zeros((news_num, args.num_words_abstract), dtype='int32') if args.use_abstract else None\n",
        "\n",
        "    for key in tqdm(news):\n",
        "        title, category, subcategory, abstract = news[key]\n",
        "        doc_index = news_index[key]\n",
        "\n",
        "        for word_id in range(min(args.num_words_title, len(title))):\n",
        "            if title[word_id] in word_dict:\n",
        "                news_title[doc_index, word_id] = word_dict[title[word_id]]\n",
        "\n",
        "        if args.use_category:\n",
        "            news_category[doc_index, 0] = category_dict[category] if category in category_dict else 0\n",
        "        if args.use_subcategory:\n",
        "            news_subcategory[doc_index, 0] = subcategory_dict[subcategory] if subcategory in subcategory_dict else 0\n",
        "        if args.use_abstract:\n",
        "            for word_id in range(min(args.num_words_abstract, len(abstract))):\n",
        "                if abstract[word_id] in word_dict:\n",
        "                    news_abstract[doc_index, word_id] = word_dict[abstract[word_id]]\n",
        "\n",
        "    return news_title, news_category, news_subcategory, news_abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MambLdtFlSxi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zXd8SNmIm34q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu43E3_6AqAA"
      },
      "source": [
        "**prepare_data.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5Qzn9-0kAuFF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import logging\n",
        "\n",
        "\n",
        "def get_sample(all_elements, num_sample):\n",
        "    if num_sample > len(all_elements):\n",
        "        return random.sample(all_elements * (num_sample // len(all_elements) + 1), num_sample)\n",
        "    else:\n",
        "        return random.sample(all_elements, num_sample)\n",
        "\n",
        "\n",
        "def prepare_training_data(train_data_dir, nGPU, npratio, seed):\n",
        "    random.seed(seed)\n",
        "    behaviors = []\n",
        "\n",
        "    behavior_file_path = os.path.join(train_data_dir, 'behaviors.tsv')\n",
        "    with open(behavior_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in tqdm(f):\n",
        "            iid, uid, time, history, imp = line.strip().split('\\t')\n",
        "            impressions = [x.split('-') for x in imp.split(' ')]\n",
        "            pos, neg = [], []\n",
        "            for news_ID, label in impressions:\n",
        "                if label == '0':\n",
        "                    neg.append(news_ID)\n",
        "                elif label == '1':\n",
        "                    pos.append(news_ID)\n",
        "            if len(pos) == 0 or len(neg) == 0:\n",
        "                continue\n",
        "            for pos_id in pos:\n",
        "                neg_candidate = get_sample(neg, npratio)\n",
        "                neg_str = ' '.join(neg_candidate)\n",
        "                new_line = '\\t'.join([iid, uid, time, history, pos_id, neg_str]) + '\\n'\n",
        "                behaviors.append(new_line)\n",
        "\n",
        "    random.shuffle(behaviors)\n",
        "\n",
        "    behaviors_per_file = [[] for _ in range(nGPU)]\n",
        "    for i, line in enumerate(behaviors):\n",
        "        behaviors_per_file[i % nGPU].append(line)\n",
        "\n",
        "    logging.info('Writing files...')\n",
        "    for i in range(nGPU):\n",
        "        processed_file_path = os.path.join(train_data_dir, f'behaviors_np{npratio}_{i}.tsv')\n",
        "        with open(processed_file_path, 'w') as f:\n",
        "            f.writelines(behaviors_per_file[i])\n",
        "\n",
        "    return len(behaviors)\n",
        "\n",
        "\n",
        "def prepare_testing_data(test_data_dir, nGPU):\n",
        "    behaviors = [[] for _ in range(nGPU)]\n",
        "\n",
        "    behavior_file_path = os.path.join(test_data_dir, 'behaviors.tsv')\n",
        "    with open(behavior_file_path, 'r', encoding='utf-8') as f:\n",
        "        for i, line in enumerate(tqdm(f)):\n",
        "            behaviors[i % nGPU].append(line)\n",
        "\n",
        "    logging.info('Writing files...')\n",
        "    for i in range(nGPU):\n",
        "        processed_file_path = os.path.join(test_data_dir, f'behaviors_{i}.tsv')\n",
        "        with open(processed_file_path, 'w') as f:\n",
        "            f.writelines(behaviors[i])\n",
        "\n",
        "    return sum([len(x) for x in behaviors])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgkOVqFzS6Uv",
        "outputId": "21c5d676-d2dc-4c6d-b2d0-7116daa3bcfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO 2025-03-03 14:19:05,978] args[batch_size]=32\n",
            "[INFO 2025-03-03 14:19:05,978] args[batch_size]=32\n",
            "[INFO 2025-03-03 14:19:05,978] args[batch_size]=32\n",
            "[INFO 2025-03-03 14:19:05,978] args[batch_size]=32\n",
            "[INFO 2025-03-03 14:19:05,978] args[batch_size]=32\n",
            "[INFO 2025-03-03 14:19:05,978] args[batch_size]=32\n",
            "[INFO 2025-03-03 14:19:05,978] args[batch_size]=32\n",
            "[INFO 2025-03-03 14:19:05,978] args[batch_size]=32\n",
            "[INFO 2025-03-03 14:19:05,986] args[category_emb_dim]=100\n",
            "[INFO 2025-03-03 14:19:05,986] args[category_emb_dim]=100\n",
            "[INFO 2025-03-03 14:19:05,986] args[category_emb_dim]=100\n",
            "[INFO 2025-03-03 14:19:05,986] args[category_emb_dim]=100\n",
            "[INFO 2025-03-03 14:19:05,986] args[category_emb_dim]=100\n",
            "[INFO 2025-03-03 14:19:05,986] args[category_emb_dim]=100\n",
            "[INFO 2025-03-03 14:19:05,986] args[category_emb_dim]=100\n",
            "[INFO 2025-03-03 14:19:05,986] args[category_emb_dim]=100\n",
            "[INFO 2025-03-03 14:19:05,996] args[drop_rate]=0.2\n",
            "[INFO 2025-03-03 14:19:05,996] args[drop_rate]=0.2\n",
            "[INFO 2025-03-03 14:19:05,996] args[drop_rate]=0.2\n",
            "[INFO 2025-03-03 14:19:05,996] args[drop_rate]=0.2\n",
            "[INFO 2025-03-03 14:19:05,996] args[drop_rate]=0.2\n",
            "[INFO 2025-03-03 14:19:05,996] args[drop_rate]=0.2\n",
            "[INFO 2025-03-03 14:19:05,996] args[drop_rate]=0.2\n",
            "[INFO 2025-03-03 14:19:05,996] args[drop_rate]=0.2\n",
            "[INFO 2025-03-03 14:19:06,008] args[enable_gpu]=False\n",
            "[INFO 2025-03-03 14:19:06,008] args[enable_gpu]=False\n",
            "[INFO 2025-03-03 14:19:06,008] args[enable_gpu]=False\n",
            "[INFO 2025-03-03 14:19:06,008] args[enable_gpu]=False\n",
            "[INFO 2025-03-03 14:19:06,008] args[enable_gpu]=False\n",
            "[INFO 2025-03-03 14:19:06,008] args[enable_gpu]=False\n",
            "[INFO 2025-03-03 14:19:06,008] args[enable_gpu]=False\n",
            "[INFO 2025-03-03 14:19:06,008] args[enable_gpu]=False\n",
            "[INFO 2025-03-03 14:19:06,018] args[epochs]=5\n",
            "[INFO 2025-03-03 14:19:06,018] args[epochs]=5\n",
            "[INFO 2025-03-03 14:19:06,018] args[epochs]=5\n",
            "[INFO 2025-03-03 14:19:06,018] args[epochs]=5\n",
            "[INFO 2025-03-03 14:19:06,018] args[epochs]=5\n",
            "[INFO 2025-03-03 14:19:06,018] args[epochs]=5\n",
            "[INFO 2025-03-03 14:19:06,018] args[epochs]=5\n",
            "[INFO 2025-03-03 14:19:06,018] args[epochs]=5\n",
            "[INFO 2025-03-03 14:19:06,027] args[filter_num]=3\n",
            "[INFO 2025-03-03 14:19:06,027] args[filter_num]=3\n",
            "[INFO 2025-03-03 14:19:06,027] args[filter_num]=3\n",
            "[INFO 2025-03-03 14:19:06,027] args[filter_num]=3\n",
            "[INFO 2025-03-03 14:19:06,027] args[filter_num]=3\n",
            "[INFO 2025-03-03 14:19:06,027] args[filter_num]=3\n",
            "[INFO 2025-03-03 14:19:06,027] args[filter_num]=3\n",
            "[INFO 2025-03-03 14:19:06,027] args[filter_num]=3\n",
            "[INFO 2025-03-03 14:19:06,036] args[freeze_embedding]=False\n",
            "[INFO 2025-03-03 14:19:06,036] args[freeze_embedding]=False\n",
            "[INFO 2025-03-03 14:19:06,036] args[freeze_embedding]=False\n",
            "[INFO 2025-03-03 14:19:06,036] args[freeze_embedding]=False\n",
            "[INFO 2025-03-03 14:19:06,036] args[freeze_embedding]=False\n",
            "[INFO 2025-03-03 14:19:06,036] args[freeze_embedding]=False\n",
            "[INFO 2025-03-03 14:19:06,036] args[freeze_embedding]=False\n",
            "[INFO 2025-03-03 14:19:06,036] args[freeze_embedding]=False\n",
            "[INFO 2025-03-03 14:19:06,042] args[glove_embedding_path]=/home/vinmike/Downloads/glove.840B.300d.txt\n",
            "[INFO 2025-03-03 14:19:06,042] args[glove_embedding_path]=/home/vinmike/Downloads/glove.840B.300d.txt\n",
            "[INFO 2025-03-03 14:19:06,042] args[glove_embedding_path]=/home/vinmike/Downloads/glove.840B.300d.txt\n",
            "[INFO 2025-03-03 14:19:06,042] args[glove_embedding_path]=/home/vinmike/Downloads/glove.840B.300d.txt\n",
            "[INFO 2025-03-03 14:19:06,042] args[glove_embedding_path]=/home/vinmike/Downloads/glove.840B.300d.txt\n",
            "[INFO 2025-03-03 14:19:06,042] args[glove_embedding_path]=/home/vinmike/Downloads/glove.840B.300d.txt\n",
            "[INFO 2025-03-03 14:19:06,042] args[glove_embedding_path]=/home/vinmike/Downloads/glove.840B.300d.txt\n",
            "[INFO 2025-03-03 14:19:06,042] args[glove_embedding_path]=/home/vinmike/Downloads/glove.840B.300d.txt\n",
            "[INFO 2025-03-03 14:19:06,054] args[load_ckpt_name]=None\n",
            "[INFO 2025-03-03 14:19:06,054] args[load_ckpt_name]=None\n",
            "[INFO 2025-03-03 14:19:06,054] args[load_ckpt_name]=None\n",
            "[INFO 2025-03-03 14:19:06,054] args[load_ckpt_name]=None\n",
            "[INFO 2025-03-03 14:19:06,054] args[load_ckpt_name]=None\n",
            "[INFO 2025-03-03 14:19:06,054] args[load_ckpt_name]=None\n",
            "[INFO 2025-03-03 14:19:06,054] args[load_ckpt_name]=None\n",
            "[INFO 2025-03-03 14:19:06,054] args[load_ckpt_name]=None\n",
            "[INFO 2025-03-03 14:19:06,063] args[log_steps]=100\n",
            "[INFO 2025-03-03 14:19:06,063] args[log_steps]=100\n",
            "[INFO 2025-03-03 14:19:06,063] args[log_steps]=100\n",
            "[INFO 2025-03-03 14:19:06,063] args[log_steps]=100\n",
            "[INFO 2025-03-03 14:19:06,063] args[log_steps]=100\n",
            "[INFO 2025-03-03 14:19:06,063] args[log_steps]=100\n",
            "[INFO 2025-03-03 14:19:06,063] args[log_steps]=100\n",
            "[INFO 2025-03-03 14:19:06,063] args[log_steps]=100\n",
            "[INFO 2025-03-03 14:19:06,073] args[lr]=0.0003\n",
            "[INFO 2025-03-03 14:19:06,073] args[lr]=0.0003\n",
            "[INFO 2025-03-03 14:19:06,073] args[lr]=0.0003\n",
            "[INFO 2025-03-03 14:19:06,073] args[lr]=0.0003\n",
            "[INFO 2025-03-03 14:19:06,073] args[lr]=0.0003\n",
            "[INFO 2025-03-03 14:19:06,073] args[lr]=0.0003\n",
            "[INFO 2025-03-03 14:19:06,073] args[lr]=0.0003\n",
            "[INFO 2025-03-03 14:19:06,073] args[lr]=0.0003\n",
            "[INFO 2025-03-03 14:19:06,083] args[mode]=train\n",
            "[INFO 2025-03-03 14:19:06,083] args[mode]=train\n",
            "[INFO 2025-03-03 14:19:06,083] args[mode]=train\n",
            "[INFO 2025-03-03 14:19:06,083] args[mode]=train\n",
            "[INFO 2025-03-03 14:19:06,083] args[mode]=train\n",
            "[INFO 2025-03-03 14:19:06,083] args[mode]=train\n",
            "[INFO 2025-03-03 14:19:06,083] args[mode]=train\n",
            "[INFO 2025-03-03 14:19:06,083] args[mode]=train\n",
            "[INFO 2025-03-03 14:19:06,094] args[model_dir]=/content/model\n",
            "[INFO 2025-03-03 14:19:06,094] args[model_dir]=/content/model\n",
            "[INFO 2025-03-03 14:19:06,094] args[model_dir]=/content/model\n",
            "[INFO 2025-03-03 14:19:06,094] args[model_dir]=/content/model\n",
            "[INFO 2025-03-03 14:19:06,094] args[model_dir]=/content/model\n",
            "[INFO 2025-03-03 14:19:06,094] args[model_dir]=/content/model\n",
            "[INFO 2025-03-03 14:19:06,094] args[model_dir]=/content/model\n",
            "[INFO 2025-03-03 14:19:06,094] args[model_dir]=/content/model\n",
            "[INFO 2025-03-03 14:19:06,104] args[nGPU]=1\n",
            "[INFO 2025-03-03 14:19:06,104] args[nGPU]=1\n",
            "[INFO 2025-03-03 14:19:06,104] args[nGPU]=1\n",
            "[INFO 2025-03-03 14:19:06,104] args[nGPU]=1\n",
            "[INFO 2025-03-03 14:19:06,104] args[nGPU]=1\n",
            "[INFO 2025-03-03 14:19:06,104] args[nGPU]=1\n",
            "[INFO 2025-03-03 14:19:06,104] args[nGPU]=1\n",
            "[INFO 2025-03-03 14:19:06,104] args[nGPU]=1\n",
            "[INFO 2025-03-03 14:19:06,119] args[news_dim]=300\n",
            "[INFO 2025-03-03 14:19:06,119] args[news_dim]=300\n",
            "[INFO 2025-03-03 14:19:06,119] args[news_dim]=300\n",
            "[INFO 2025-03-03 14:19:06,119] args[news_dim]=300\n",
            "[INFO 2025-03-03 14:19:06,119] args[news_dim]=300\n",
            "[INFO 2025-03-03 14:19:06,119] args[news_dim]=300\n",
            "[INFO 2025-03-03 14:19:06,119] args[news_dim]=300\n",
            "[INFO 2025-03-03 14:19:06,119] args[news_dim]=300\n",
            "[INFO 2025-03-03 14:19:06,127] args[news_query_vector_dim]=200\n",
            "[INFO 2025-03-03 14:19:06,127] args[news_query_vector_dim]=200\n",
            "[INFO 2025-03-03 14:19:06,127] args[news_query_vector_dim]=200\n",
            "[INFO 2025-03-03 14:19:06,127] args[news_query_vector_dim]=200\n",
            "[INFO 2025-03-03 14:19:06,127] args[news_query_vector_dim]=200\n",
            "[INFO 2025-03-03 14:19:06,127] args[news_query_vector_dim]=200\n",
            "[INFO 2025-03-03 14:19:06,127] args[news_query_vector_dim]=200\n",
            "[INFO 2025-03-03 14:19:06,127] args[news_query_vector_dim]=200\n",
            "[INFO 2025-03-03 14:19:06,135] args[npratio]=4\n",
            "[INFO 2025-03-03 14:19:06,135] args[npratio]=4\n",
            "[INFO 2025-03-03 14:19:06,135] args[npratio]=4\n",
            "[INFO 2025-03-03 14:19:06,135] args[npratio]=4\n",
            "[INFO 2025-03-03 14:19:06,135] args[npratio]=4\n",
            "[INFO 2025-03-03 14:19:06,135] args[npratio]=4\n",
            "[INFO 2025-03-03 14:19:06,135] args[npratio]=4\n",
            "[INFO 2025-03-03 14:19:06,135] args[npratio]=4\n",
            "[INFO 2025-03-03 14:19:06,144] args[num_attention_heads]=15\n",
            "[INFO 2025-03-03 14:19:06,144] args[num_attention_heads]=15\n",
            "[INFO 2025-03-03 14:19:06,144] args[num_attention_heads]=15\n",
            "[INFO 2025-03-03 14:19:06,144] args[num_attention_heads]=15\n",
            "[INFO 2025-03-03 14:19:06,144] args[num_attention_heads]=15\n",
            "[INFO 2025-03-03 14:19:06,144] args[num_attention_heads]=15\n",
            "[INFO 2025-03-03 14:19:06,144] args[num_attention_heads]=15\n",
            "[INFO 2025-03-03 14:19:06,144] args[num_attention_heads]=15\n",
            "[INFO 2025-03-03 14:19:06,156] args[num_words_abstract]=50\n",
            "[INFO 2025-03-03 14:19:06,156] args[num_words_abstract]=50\n",
            "[INFO 2025-03-03 14:19:06,156] args[num_words_abstract]=50\n",
            "[INFO 2025-03-03 14:19:06,156] args[num_words_abstract]=50\n",
            "[INFO 2025-03-03 14:19:06,156] args[num_words_abstract]=50\n",
            "[INFO 2025-03-03 14:19:06,156] args[num_words_abstract]=50\n",
            "[INFO 2025-03-03 14:19:06,156] args[num_words_abstract]=50\n",
            "[INFO 2025-03-03 14:19:06,156] args[num_words_abstract]=50\n",
            "[INFO 2025-03-03 14:19:06,164] args[num_words_title]=20\n",
            "[INFO 2025-03-03 14:19:06,164] args[num_words_title]=20\n",
            "[INFO 2025-03-03 14:19:06,164] args[num_words_title]=20\n",
            "[INFO 2025-03-03 14:19:06,164] args[num_words_title]=20\n",
            "[INFO 2025-03-03 14:19:06,164] args[num_words_title]=20\n",
            "[INFO 2025-03-03 14:19:06,164] args[num_words_title]=20\n",
            "[INFO 2025-03-03 14:19:06,164] args[num_words_title]=20\n",
            "[INFO 2025-03-03 14:19:06,164] args[num_words_title]=20\n",
            "[INFO 2025-03-03 14:19:06,173] args[prepare]=True\n",
            "[INFO 2025-03-03 14:19:06,173] args[prepare]=True\n",
            "[INFO 2025-03-03 14:19:06,173] args[prepare]=True\n",
            "[INFO 2025-03-03 14:19:06,173] args[prepare]=True\n",
            "[INFO 2025-03-03 14:19:06,173] args[prepare]=True\n",
            "[INFO 2025-03-03 14:19:06,173] args[prepare]=True\n",
            "[INFO 2025-03-03 14:19:06,173] args[prepare]=True\n",
            "[INFO 2025-03-03 14:19:06,173] args[prepare]=True\n",
            "[INFO 2025-03-03 14:19:06,184] args[save_steps]=10000\n",
            "[INFO 2025-03-03 14:19:06,184] args[save_steps]=10000\n",
            "[INFO 2025-03-03 14:19:06,184] args[save_steps]=10000\n",
            "[INFO 2025-03-03 14:19:06,184] args[save_steps]=10000\n",
            "[INFO 2025-03-03 14:19:06,184] args[save_steps]=10000\n",
            "[INFO 2025-03-03 14:19:06,184] args[save_steps]=10000\n",
            "[INFO 2025-03-03 14:19:06,184] args[save_steps]=10000\n",
            "[INFO 2025-03-03 14:19:06,184] args[save_steps]=10000\n",
            "[INFO 2025-03-03 14:19:06,191] args[seed]=0\n",
            "[INFO 2025-03-03 14:19:06,191] args[seed]=0\n",
            "[INFO 2025-03-03 14:19:06,191] args[seed]=0\n",
            "[INFO 2025-03-03 14:19:06,191] args[seed]=0\n",
            "[INFO 2025-03-03 14:19:06,191] args[seed]=0\n",
            "[INFO 2025-03-03 14:19:06,191] args[seed]=0\n",
            "[INFO 2025-03-03 14:19:06,191] args[seed]=0\n",
            "[INFO 2025-03-03 14:19:06,191] args[seed]=0\n",
            "[INFO 2025-03-03 14:19:06,199] args[start_epoch]=0\n",
            "[INFO 2025-03-03 14:19:06,199] args[start_epoch]=0\n",
            "[INFO 2025-03-03 14:19:06,199] args[start_epoch]=0\n",
            "[INFO 2025-03-03 14:19:06,199] args[start_epoch]=0\n",
            "[INFO 2025-03-03 14:19:06,199] args[start_epoch]=0\n",
            "[INFO 2025-03-03 14:19:06,199] args[start_epoch]=0\n",
            "[INFO 2025-03-03 14:19:06,199] args[start_epoch]=0\n",
            "[INFO 2025-03-03 14:19:06,199] args[start_epoch]=0\n",
            "[INFO 2025-03-03 14:19:06,211] args[test_abstract_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json\n",
            "[INFO 2025-03-03 14:19:06,211] args[test_abstract_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json\n",
            "[INFO 2025-03-03 14:19:06,211] args[test_abstract_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json\n",
            "[INFO 2025-03-03 14:19:06,211] args[test_abstract_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json\n",
            "[INFO 2025-03-03 14:19:06,211] args[test_abstract_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json\n",
            "[INFO 2025-03-03 14:19:06,211] args[test_abstract_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json\n",
            "[INFO 2025-03-03 14:19:06,211] args[test_abstract_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json\n",
            "[INFO 2025-03-03 14:19:06,211] args[test_abstract_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json\n",
            "[INFO 2025-03-03 14:19:06,221] args[test_data_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_dev\n",
            "[INFO 2025-03-03 14:19:06,221] args[test_data_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_dev\n",
            "[INFO 2025-03-03 14:19:06,221] args[test_data_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_dev\n",
            "[INFO 2025-03-03 14:19:06,221] args[test_data_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_dev\n",
            "[INFO 2025-03-03 14:19:06,221] args[test_data_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_dev\n",
            "[INFO 2025-03-03 14:19:06,221] args[test_data_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_dev\n",
            "[INFO 2025-03-03 14:19:06,221] args[test_data_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_dev\n",
            "[INFO 2025-03-03 14:19:06,221] args[test_data_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_dev\n",
            "[INFO 2025-03-03 14:19:06,231] args[train_abstract_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json\n",
            "[INFO 2025-03-03 14:19:06,231] args[train_abstract_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json\n",
            "[INFO 2025-03-03 14:19:06,231] args[train_abstract_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json\n",
            "[INFO 2025-03-03 14:19:06,231] args[train_abstract_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json\n",
            "[INFO 2025-03-03 14:19:06,231] args[train_abstract_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json\n",
            "[INFO 2025-03-03 14:19:06,231] args[train_abstract_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json\n",
            "[INFO 2025-03-03 14:19:06,231] args[train_abstract_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json\n",
            "[INFO 2025-03-03 14:19:06,231] args[train_abstract_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/genAbs0.json\n",
            "[INFO 2025-03-03 14:19:06,252] args[train_data_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_train\n",
            "[INFO 2025-03-03 14:19:06,252] args[train_data_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_train\n",
            "[INFO 2025-03-03 14:19:06,252] args[train_data_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_train\n",
            "[INFO 2025-03-03 14:19:06,252] args[train_data_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_train\n",
            "[INFO 2025-03-03 14:19:06,252] args[train_data_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_train\n",
            "[INFO 2025-03-03 14:19:06,252] args[train_data_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_train\n",
            "[INFO 2025-03-03 14:19:06,252] args[train_data_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_train\n",
            "[INFO 2025-03-03 14:19:06,252] args[train_data_dir]=/home/vinmike/Documents/GitHub/LLM4Rec-Dataloader/data/MINDsmall_train\n",
            "[INFO 2025-03-03 14:19:06,272] args[use_abstract]=True\n",
            "[INFO 2025-03-03 14:19:06,272] args[use_abstract]=True\n",
            "[INFO 2025-03-03 14:19:06,272] args[use_abstract]=True\n",
            "[INFO 2025-03-03 14:19:06,272] args[use_abstract]=True\n",
            "[INFO 2025-03-03 14:19:06,272] args[use_abstract]=True\n",
            "[INFO 2025-03-03 14:19:06,272] args[use_abstract]=True\n",
            "[INFO 2025-03-03 14:19:06,272] args[use_abstract]=True\n",
            "[INFO 2025-03-03 14:19:06,272] args[use_abstract]=True\n",
            "[INFO 2025-03-03 14:19:06,282] args[use_category]=True\n",
            "[INFO 2025-03-03 14:19:06,282] args[use_category]=True\n",
            "[INFO 2025-03-03 14:19:06,282] args[use_category]=True\n",
            "[INFO 2025-03-03 14:19:06,282] args[use_category]=True\n",
            "[INFO 2025-03-03 14:19:06,282] args[use_category]=True\n",
            "[INFO 2025-03-03 14:19:06,282] args[use_category]=True\n",
            "[INFO 2025-03-03 14:19:06,282] args[use_category]=True\n",
            "[INFO 2025-03-03 14:19:06,282] args[use_category]=True\n",
            "[INFO 2025-03-03 14:19:06,300] args[use_custom_abstract]=True\n",
            "[INFO 2025-03-03 14:19:06,300] args[use_custom_abstract]=True\n",
            "[INFO 2025-03-03 14:19:06,300] args[use_custom_abstract]=True\n",
            "[INFO 2025-03-03 14:19:06,300] args[use_custom_abstract]=True\n",
            "[INFO 2025-03-03 14:19:06,300] args[use_custom_abstract]=True\n",
            "[INFO 2025-03-03 14:19:06,300] args[use_custom_abstract]=True\n",
            "[INFO 2025-03-03 14:19:06,300] args[use_custom_abstract]=True\n",
            "[INFO 2025-03-03 14:19:06,300] args[use_custom_abstract]=True\n",
            "[INFO 2025-03-03 14:19:06,311] args[use_subcategory]=True\n",
            "[INFO 2025-03-03 14:19:06,311] args[use_subcategory]=True\n",
            "[INFO 2025-03-03 14:19:06,311] args[use_subcategory]=True\n",
            "[INFO 2025-03-03 14:19:06,311] args[use_subcategory]=True\n",
            "[INFO 2025-03-03 14:19:06,311] args[use_subcategory]=True\n",
            "[INFO 2025-03-03 14:19:06,311] args[use_subcategory]=True\n",
            "[INFO 2025-03-03 14:19:06,311] args[use_subcategory]=True\n",
            "[INFO 2025-03-03 14:19:06,311] args[use_subcategory]=True\n",
            "[INFO 2025-03-03 14:19:06,325] args[user_log_length]=50\n",
            "[INFO 2025-03-03 14:19:06,325] args[user_log_length]=50\n",
            "[INFO 2025-03-03 14:19:06,325] args[user_log_length]=50\n",
            "[INFO 2025-03-03 14:19:06,325] args[user_log_length]=50\n",
            "[INFO 2025-03-03 14:19:06,325] args[user_log_length]=50\n",
            "[INFO 2025-03-03 14:19:06,325] args[user_log_length]=50\n",
            "[INFO 2025-03-03 14:19:06,325] args[user_log_length]=50\n",
            "[INFO 2025-03-03 14:19:06,325] args[user_log_length]=50\n",
            "[INFO 2025-03-03 14:19:06,337] args[user_log_mask]=False\n",
            "[INFO 2025-03-03 14:19:06,337] args[user_log_mask]=False\n",
            "[INFO 2025-03-03 14:19:06,337] args[user_log_mask]=False\n",
            "[INFO 2025-03-03 14:19:06,337] args[user_log_mask]=False\n",
            "[INFO 2025-03-03 14:19:06,337] args[user_log_mask]=False\n",
            "[INFO 2025-03-03 14:19:06,337] args[user_log_mask]=False\n",
            "[INFO 2025-03-03 14:19:06,337] args[user_log_mask]=False\n",
            "[INFO 2025-03-03 14:19:06,337] args[user_log_mask]=False\n",
            "[INFO 2025-03-03 14:19:06,348] args[user_query_vector_dim]=200\n",
            "[INFO 2025-03-03 14:19:06,348] args[user_query_vector_dim]=200\n",
            "[INFO 2025-03-03 14:19:06,348] args[user_query_vector_dim]=200\n",
            "[INFO 2025-03-03 14:19:06,348] args[user_query_vector_dim]=200\n",
            "[INFO 2025-03-03 14:19:06,348] args[user_query_vector_dim]=200\n",
            "[INFO 2025-03-03 14:19:06,348] args[user_query_vector_dim]=200\n",
            "[INFO 2025-03-03 14:19:06,348] args[user_query_vector_dim]=200\n",
            "[INFO 2025-03-03 14:19:06,348] args[user_query_vector_dim]=200\n",
            "[INFO 2025-03-03 14:19:06,362] args[word_embedding_dim]=300\n",
            "[INFO 2025-03-03 14:19:06,362] args[word_embedding_dim]=300\n",
            "[INFO 2025-03-03 14:19:06,362] args[word_embedding_dim]=300\n",
            "[INFO 2025-03-03 14:19:06,362] args[word_embedding_dim]=300\n",
            "[INFO 2025-03-03 14:19:06,362] args[word_embedding_dim]=300\n",
            "[INFO 2025-03-03 14:19:06,362] args[word_embedding_dim]=300\n",
            "[INFO 2025-03-03 14:19:06,362] args[word_embedding_dim]=300\n",
            "[INFO 2025-03-03 14:19:06,362] args[word_embedding_dim]=300\n"
          ]
        }
      ],
      "source": [
        "\n",
        "    import subprocess\n",
        "    setuplogger()\n",
        "    args = parse_args()\n",
        "    dump_args(args)\n",
        "    random.seed(args.seed)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5694OJnDLmEV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkoY3tHH6in5"
      },
      "source": [
        "# **NRMS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "KXeVVGPl6sgG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class DotProductClickPredictor(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DotProductClickPredictor, self).__init__()\n",
        "\n",
        "    def forward(self, candidate_news_vector, user_vector):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            candidate_news_vector: batch_size, candidate_size, X\n",
        "            user_vector: batch_size, X\n",
        "        Returns:\n",
        "            (shape): batch_size\n",
        "        \"\"\"\n",
        "        # batch_size, candidate_size\n",
        "        probability = torch.bmm(candidate_news_vector,\n",
        "                                user_vector.unsqueeze(dim=-1)).squeeze(dim=-1)\n",
        "        return probability\n",
        "class AdditiveAttention(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A general additive attention module.\n",
        "    Originally for NAML.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 query_vector_dim,\n",
        "                 candidate_vector_dim,\n",
        "                 writer=None,\n",
        "                 tag=None,\n",
        "                 names=None):\n",
        "        super(AdditiveAttention, self).__init__()\n",
        "        self.linear = nn.Linear(candidate_vector_dim, query_vector_dim)\n",
        "        self.attention_query_vector = nn.Parameter(\n",
        "            torch.empty(query_vector_dim).uniform_(-0.1, 0.1))\n",
        "        # For tensorboard\n",
        "        self.writer = writer\n",
        "        self.tag = tag\n",
        "        self.names = names\n",
        "        self.local_step = 1\n",
        "\n",
        "    def forward(self, candidate_vector):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            candidate_vector: batch_size, candidate_size, candidate_vector_dim\n",
        "        Returns:\n",
        "            (shape) batch_size, candidate_vector_dim\n",
        "        \"\"\"\n",
        "        # batch_size, candidate_size, query_vector_dim\n",
        "        temp = torch.tanh(self.linear(candidate_vector))\n",
        "        # batch_size, candidate_size\n",
        "        candidate_weights = F.softmax(torch.matmul(\n",
        "            temp, self.attention_query_vector),\n",
        "                                      dim=1)\n",
        "        if self.writer is not None:\n",
        "            assert candidate_weights.size(1) == len(self.names)\n",
        "            if self.local_step % 10 == 0:\n",
        "                self.writer.add_scalars(\n",
        "                    self.tag, {\n",
        "                        x: y\n",
        "                        for x, y in zip(self.names,\n",
        "                                        candidate_weights.mean(dim=0))\n",
        "                    }, self.local_step)\n",
        "            self.local_step += 1\n",
        "        # batch_size, candidate_vector_dim\n",
        "        target = torch.bmm(candidate_weights.unsqueeze(dim=1),\n",
        "                           candidate_vector).squeeze(dim=1)\n",
        "        return target\n",
        "    \n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, d_k):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "        self.d_k = d_k\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask=None):\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.d_k)\n",
        "        scores = torch.exp(scores)\n",
        "        if attn_mask is not None:\n",
        "            scores = scores * attn_mask\n",
        "        attn = scores / (torch.sum(scores, dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "        context = torch.matmul(attn, V)\n",
        "        return context, attn\n",
        "\n",
        "\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_attention_heads):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        assert d_model % num_attention_heads == 0\n",
        "        self.d_k = d_model // num_attention_heads\n",
        "        self.d_v = d_model // num_attention_heads\n",
        "\n",
        "        self.W_Q = nn.Linear(d_model, d_model)\n",
        "        self.W_K = nn.Linear(d_model, d_model)\n",
        "        self.W_V = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight, gain=1)\n",
        "\n",
        "    def forward(self, Q, K=None, V=None, length=None):\n",
        "        if K is None:\n",
        "            K = Q\n",
        "        if V is None:\n",
        "            V = Q\n",
        "        batch_size = Q.size(0)\n",
        "\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.num_attention_heads,\n",
        "                               self.d_k).transpose(1, 2)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.num_attention_heads,\n",
        "                               self.d_k).transpose(1, 2)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.num_attention_heads,\n",
        "                               self.d_v).transpose(1, 2)\n",
        "\n",
        "        if length is not None:\n",
        "            maxlen = Q.size(1)\n",
        "            attn_mask = torch.arange(maxlen).expand(\n",
        "                batch_size, maxlen) < length.view(-1, 1)\n",
        "            attn_mask = attn_mask.unsqueeze(1).expand(batch_size, maxlen,\n",
        "                                                      maxlen)\n",
        "            attn_mask = attn_mask.unsqueeze(1).repeat(1,\n",
        "                                                      self.num_attention_heads,\n",
        "                                                      1, 1)\n",
        "        else:\n",
        "            attn_mask = None\n",
        "\n",
        "        context, attn = ScaledDotProductAttention(self.d_k)(q_s, k_s, v_s,\n",
        "                                                            attn_mask)\n",
        "        context = context.transpose(1, 2).contiguous().view(\n",
        "            batch_size, -1, self.num_attention_heads * self.d_v)\n",
        "        return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "l3W3JjCZ6k1a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NewsEncoder(nn.Module):\n",
        "    def __init__(self, args, embedding_matrix, num_category, num_subcategory):\n",
        "        super(NewsEncoder, self).__init__()\n",
        "        self.embedding_matrix = embedding_matrix\n",
        "        self.drop_rate = args.drop_rate\n",
        "        self.num_words_title = args.num_words_title\n",
        "        self.num_words_abstract = args.num_words_abstract\n",
        "        self.news_dim = args.news_dim\n",
        "        self.word_embedding_dim = args.word_embedding_dim\n",
        "\n",
        "        self.multi_head_self_attn = MultiHeadSelfAttention(args.word_embedding_dim, args.num_attention_heads)\n",
        "        self.attn = AdditiveAttention(args.news_query_vector_dim, args.word_embedding_dim)\n",
        "\n",
        "        # Category & Subcategory Embeddings\n",
        "        self.use_category = args.use_category\n",
        "        self.use_subcategory = args.use_subcategory\n",
        "        self.use_abstract = args.use_abstract\n",
        "\n",
        "        self.category_emb = nn.Embedding(num_category + 1, args.category_emb_dim, padding_idx=0) if self.use_category else None\n",
        "        self.subcategory_emb = nn.Embedding(num_subcategory + 1, args.category_emb_dim, padding_idx=0) if self.use_subcategory else None\n",
        "\n",
        "        # Projection layers to match news_dim\n",
        "        self.category_dense = nn.Linear(args.category_emb_dim, self.news_dim) if self.use_category else None\n",
        "        self.subcategory_dense = nn.Linear(args.category_emb_dim, self.news_dim) if self.use_subcategory else None\n",
        "        \n",
        "        if self.use_abstract:\n",
        "            self.abstract_multi_head_self_attn = MultiHeadSelfAttention(args.word_embedding_dim, args.num_attention_heads)\n",
        "            self.abstract_attn = AdditiveAttention(args.news_query_vector_dim, args.word_embedding_dim)\n",
        "\n",
        "        # Adjusting feature multiplier for correct shape\n",
        "        feature_multiplier = 1 + int(self.use_category) + int(self.use_subcategory) + int(self.use_abstract)\n",
        "        print(\"Feature Multiplier:\", feature_multiplier)\n",
        "        self.fusion_layer = nn.Linear(1200, self.news_dim)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        all_vecs = []\n",
        "\n",
        "        # Encode Title\n",
        "        title = x[:, :self.num_words_title].long()\n",
        "        word_vecs = F.dropout(self.embedding_matrix(title), p=self.drop_rate, training=self.training)\n",
        "        multihead_text_vecs = self.multi_head_self_attn(word_vecs, word_vecs, word_vecs, mask)\n",
        "        multihead_text_vecs = F.dropout(multihead_text_vecs, p=self.drop_rate, training=self.training)\n",
        "        title_vecs = self.attn(multihead_text_vecs)\n",
        "        all_vecs.append(title_vecs)\n",
        "        \n",
        "        start = self.num_words_title\n",
        "\n",
        "        # Encode Category\n",
        "        if self.use_category:\n",
        "            category = x[:, start].long()\n",
        "            category_vecs = F.relu(self.category_dense(self.category_emb(category)))\n",
        "            all_vecs.append(category_vecs)\n",
        "            start += 1\n",
        "\n",
        "        # Encode Subcategory\n",
        "        if self.use_subcategory:\n",
        "            subcategory = x[:, start].long()\n",
        "            subcategory_vecs = F.relu(self.subcategory_dense(self.subcategory_emb(subcategory)))\n",
        "            all_vecs.append(subcategory_vecs)\n",
        "            start += 1\n",
        "\n",
        "        # Encode Abstract\n",
        "        if self.use_abstract:\n",
        "            abstract = x[:, start:start + self.num_words_abstract].long()\n",
        "            abstract_word_vecs = F.dropout(self.embedding_matrix(abstract), p=self.drop_rate, training=self.training)\n",
        "            abstract_multihead_text_vecs = self.abstract_multi_head_self_attn(abstract_word_vecs, abstract_word_vecs, abstract_word_vecs, mask)\n",
        "            abstract_multihead_text_vecs = F.dropout(abstract_multihead_text_vecs, p=self.drop_rate, training=self.training)\n",
        "            abstract_vecs = self.abstract_attn(abstract_multihead_text_vecs)\n",
        "            all_vecs.append(abstract_vecs)\n",
        "        \n",
        "        # Concatenate Features and Apply Final Fusion\n",
        "        news_vecs = torch.cat(all_vecs, dim=-1)\n",
        "        print(news_vecs.shape) \n",
        "        news_vecs = self.fusion_layer(news_vecs)\n",
        "        \n",
        "        return news_vecs\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "class UserEncoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(UserEncoder, self).__init__()\n",
        "        self.args = args\n",
        "        self.dim_per_head = args.news_dim // args.num_attention_heads\n",
        "        self.multi_head_self_attn = MultiHeadSelfAttention(args.word_embedding_dim, args.num_attention_heads)\n",
        "        self.attn = AdditiveAttention(args.user_query_vector_dim, args.word_embedding_dim)\n",
        "        self.pad_doc = nn.Parameter(torch.empty(1, args.news_dim).uniform_(-1, 1)).type(torch.FloatTensor)\n",
        "\n",
        "    def forward(self, user_vector):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            user_vector: batch_size, num_clicked_news_a_user, word_embedding_dim\n",
        "        Returns:\n",
        "            (shape) batch_size, word_embedding_dim\n",
        "        \"\"\"\n",
        "        # batch_size, num_clicked_news_a_user, word_embedding_dim\n",
        "        multihead_user_vector = self.multi_head_self_attn(user_vector)\n",
        "        # batch_size, word_embedding_dim\n",
        "        final_user_vector = self.attn(multihead_user_vector)\n",
        "        return final_user_vector\n",
        "    \n",
        "\n",
        "\n",
        "class NRMS(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    NRMS network.\n",
        "    Input 1 + K candidate news and a list of user clicked news, produce the click probability.\n",
        "    \"\"\"\n",
        "    def __init__(self, config, embedding_matrix, num_category, num_subcategory):\n",
        "        super(NRMS, self).__init__()\n",
        "        self.config = config\n",
        "        word_embedding = torch.from_numpy(embedding_matrix).float()\n",
        "        pretrained_word_embedding = nn.Embedding.from_pretrained(word_embedding,\n",
        "                                                      freeze=args.freeze_embedding,\n",
        "                                                      padding_idx=0)\n",
        " \n",
        "        self.news_encoder = NewsEncoder(config, pretrained_word_embedding, num_category, num_subcategory)\n",
        "        self.user_encoder = UserEncoder(config)\n",
        "        self.click_predictor = DotProductClickPredictor()\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, clicked_news, candidate_news, label):\n",
        "        \n",
        "        # batch_size, 1 + K, word_embedding_dim\n",
        "        candidate_news_vector = torch.stack(\n",
        "            [self.news_encoder(x) for x in candidate_news])\n",
        "        \n",
        "        # batch_size, num_clicked_news_a_user, word_embedding_dim\n",
        "        clicked_news_vector = torch.stack(\n",
        "            [self.news_encoder(x) for x in clicked_news])\n",
        "        \n",
        "        # batch_size, word_embedding_dim\n",
        "        user_vector = self.user_encoder(clicked_news_vector)\n",
        "\n",
        "        # batch_size, 1 + K\n",
        "        click_probability = self.click_predictor(candidate_news_vector,\n",
        "                                                 user_vector)\n",
        "        loss = self.loss_fn(click_probability, label)\n",
        "        # loss = 0.5\n",
        "        return loss, click_probability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OZngQdLK9Xfa"
      },
      "outputs": [],
      "source": [
        "args.mode = 'train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ms-iPzD63S-",
        "outputId": "d88b5bd8-a142-4980-e8ce-f760e6068a8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO 2025-03-03 13:23:02,746] Preparing training data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "156965it [00:06, 24355.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO 2025-03-03 13:23:09,622] Writing files...\n",
            "[INFO 2025-03-03 13:23:10,348] 236344 training samples, 7385 batches in total.\n"
          ]
        }
      ],
      "source": [
        "if 'train' in args.mode:\n",
        "    if args.prepare:\n",
        "        logging.info('Preparing training data...')\n",
        "        total_sample_num = prepare_training_data(args.train_data_dir, args.nGPU, args.npratio, args.seed)\n",
        "    else:\n",
        "        total_sample_num = 0\n",
        "        for i in range(args.nGPU):\n",
        "            data_file_path = os.path.join(args.train_data_dir, f'behaviors_np{args.npratio}_{i}.tsv')\n",
        "            print(data_file_path)\n",
        "            if not os.path.exists(data_file_path):\n",
        "                logging.error(f'Splited training data {data_file_path} for GPU {i} does not exist. Please set the parameter --prepare as True and rerun the code.')\n",
        "                exit()\n",
        "            result = subprocess.getoutput(f'wc -l {data_file_path}')\n",
        "            total_sample_num += int(result.split(' ')[0])\n",
        "        logging.info('Skip training data preparation.')\n",
        "    logging.info(f'{total_sample_num} training samples, {total_sample_num // args.batch_size // args.nGPU} batches in total.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "51282it [00:08, 6072.64it/s]\n",
            "100%|██████████| 51282/51282 [00:00<00:00, 82586.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO 2025-03-03 13:23:31,969] Initializing word embedding matrix...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO 2025-03-03 13:24:40,261] Word dict length: 12519\n",
            "[INFO 2025-03-03 13:24:40,262] Have words: 11960\n",
            "[INFO 2025-03-03 13:24:40,263] Missing rate: 0.0446521287642783\n"
          ]
        }
      ],
      "source": [
        "rank = 0\n",
        "news, news_index, category_dict, subcategory_dict, word_dict = read_news(\n",
        "\t\tos.path.join(args.train_data_dir, 'news.tsv'), args.train_abstract_dir, args, mode='train')\n",
        "\n",
        "news_title, news_category, news_subcategory, news_abstract = get_doc_input(\n",
        "    news, news_index, category_dict, subcategory_dict, word_dict, args)\n",
        "news_combined = np.concatenate([x for x in [news_title, news_category, news_subcategory, news_abstract] if x is not None], axis=-1)\n",
        "\n",
        "if rank == 0:\n",
        "    logging.info('Initializing word embedding matrix...')\n",
        "\n",
        "embedding_matrix, have_word = load_matrix(args.glove_embedding_path,\n",
        "                                                word_dict,\n",
        "                                                args.word_embedding_dim)\n",
        "if rank == 0:\n",
        "    logging.info(f'Word dict length: {len(word_dict)}')\n",
        "    logging.info(f'Have words: {len(have_word)}')\n",
        "    logging.info(f'Missing rate: {(len(word_dict) - len(have_word)) / len(word_dict)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qt4Qsf_r9RA_",
        "outputId": "f54e7ea2-1df5-49fc-d9af-75d422e45144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Multiplier: 4\n",
            "[INFO 2025-03-03 14:19:11,715] Training...\n",
            "[INFO 2025-03-03 14:19:11,715] Training...\n",
            "[INFO 2025-03-03 14:19:11,715] Training...\n",
            "[INFO 2025-03-03 14:19:11,715] Training...\n",
            "[INFO 2025-03-03 14:19:11,715] Training...\n",
            "[INFO 2025-03-03 14:19:11,715] Training...\n",
            "[INFO 2025-03-03 14:19:11,715] Training...\n",
            "[INFO 2025-03-03 14:19:11,715] Training...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([50, 1200])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (50x1200 and 1400x300)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[82], line 36\u001b[0m\n\u001b[1;32m     32\u001b[0m \tinput_ids \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mcuda(rank, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     33\u001b[0m \ttargets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mcuda(rank, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 36\u001b[0m bz_loss, y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m bz_loss\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     38\u001b[0m accuary \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc(targets, y_hat)\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[77], line 137\u001b[0m, in \u001b[0;36mNRMS.forward\u001b[0;34m(self, clicked_news, candidate_news, label)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, clicked_news, candidate_news, label):\n\u001b[1;32m    134\u001b[0m     \n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# batch_size, 1 + K, word_embedding_dim\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     candidate_news_vector \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[0;32m--> 137\u001b[0m         [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnews_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m candidate_news])\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# batch_size, num_clicked_news_a_user, word_embedding_dim\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     clicked_news_vector \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[1;32m    141\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnews_encoder(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m clicked_news])\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[77], line 84\u001b[0m, in \u001b[0;36mNewsEncoder.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     82\u001b[0m news_vecs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(all_vecs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(news_vecs\u001b[38;5;241m.\u001b[39mshape) \n\u001b[0;32m---> 84\u001b[0m news_vecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfusion_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews_vecs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m news_vecs\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (50x1200 and 1400x300)"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = NRMS(args, embedding_matrix, len(category_dict), len(subcategory_dict))\n",
        "is_distributed = False\n",
        "if args.load_ckpt_name is not None:\n",
        "\tckpt_path = get_checkpoint(args.model_dir, args.load_ckpt_name)\n",
        "\tcheckpoint = torch.load(ckpt_path, map_location='cpu')\n",
        "\tmodel.load_state_dict(checkpoint['model_state_dict'])\n",
        "\tlogging.info(f\"Model loaded from {ckpt_path}.\")\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "if args.enable_gpu:\n",
        "\tmodel = model.cuda(rank)\n",
        "\n",
        "if is_distributed:\n",
        "\tmodel = torch.nn.parallel.DistributedDataParallel(model, device_ids=[rank])\n",
        "\n",
        "data_file_path = os.path.join(args.train_data_dir, f'behaviors_np{args.npratio}_{rank}.tsv')\n",
        "\n",
        "dataset = DatasetTrain(data_file_path, news_index, news_combined, args)\n",
        "dataloader = DataLoader(dataset, batch_size=args.batch_size)\n",
        "\n",
        "logging.info('Training...')\n",
        "for ep in range(args.start_epoch, args.epochs):\n",
        "\tloss = 0.0\n",
        "\taccuary = 0.0\n",
        "\tfor cnt, (log_ids, input_ids, targets) in enumerate(dataloader):\n",
        "\t\tif args.enable_gpu:\n",
        "\t\t\tlog_ids = log_ids.cuda(rank, non_blocking=True)\n",
        "\t\t\t# log_mask = log_mask.cuda(rank, non_blocking=True)\n",
        "\t\t\tinput_ids = input_ids.cuda(rank, non_blocking=True)\n",
        "\t\t\ttargets = targets.cuda(rank, non_blocking=True)\n",
        "\t\t\t\n",
        "\t\t\n",
        "\t\tbz_loss, y_hat = model(log_ids, input_ids, targets)\n",
        "\t\tloss += bz_loss.data.float()\n",
        "\t\taccuary += acc(targets, y_hat)\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tbz_loss.backward()\n",
        "\t\toptimizer.step()\n",
        "\n",
        "\t\tif cnt % args.log_steps == 0:\n",
        "\t\t\tlogging.info(\n",
        "\t\t\t\t'[{}] Ed: {}, train_loss: {:.5f}, acc: {:.5f}'.format(\n",
        "\t\t\t\t\trank, cnt * args.batch_size, loss.data / cnt, accuary / cnt)\n",
        "\t\t\t)\n",
        "\n",
        "\t\tif rank == 0 and cnt != 0 and cnt % args.save_steps == 0:\n",
        "\t\t\tckpt_path = os.path.join(args.model_dir, f'epoch-{ep+1}-{cnt}.pt')\n",
        "\t\t\ttorch.save(\n",
        "\t\t\t\t{\n",
        "\t\t\t\t\t'model_state_dict':\n",
        "\t\t\t\t\t\t{'.'.join(k.split('.')[1:]): v for k, v in model.state_dict().items()}\n",
        "\t\t\t\t\t\tif is_distributed else model.state_dict(),\n",
        "\t\t\t\t\t'category_dict': category_dict,\n",
        "\t\t\t\t\t'word_dict': word_dict,\n",
        "\t\t\t\t\t'subcategory_dict': subcategory_dict\n",
        "\t\t\t\t}, ckpt_path)\n",
        "\t\t\tlogging.info(f\"Model saved to {ckpt_path}.\")\n",
        "\n",
        "\tlogging.info('Training finish.')\n",
        "\n",
        "\tif rank == 0:\n",
        "\t\tckpt_path = os.path.join(args.model_dir, f'epoch-{ep+1}.pt')\n",
        "\t\ttorch.save(\n",
        "\t\t\t{\n",
        "\t\t\t\t'model_state_dict':\n",
        "\t\t\t\t\t{'.'.join(k.split('.')[1:]): v for k, v in model.state_dict().items()}\n",
        "\t\t\t\t\tif is_distributed else model.state_dict(),\n",
        "\t\t\t\t'category_dict': category_dict,\n",
        "\t\t\t\t'subcategory_dict': subcategory_dict,\n",
        "\t\t\t\t'word_dict': word_dict,\n",
        "\t\t\t}, ckpt_path)\n",
        "\t\tlogging.info(f\"Model saved to {ckpt_path}.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "42416it [00:02, 15393.26it/s]\n",
            "100%|██████████| 42416/42416 [00:00<00:00, 188532.42it/s]\n"
          ]
        }
      ],
      "source": [
        "args.mode = 'test'\n",
        "args.user_log_mask=True\n",
        "args.batch_size=128\n",
        "args.load_ckpt_name= 'epoch-5.pt'\n",
        "rank = 0\n",
        "checkpoint = torch.load('/home/vinmike/Downloads/epoch-5.pt', map_location='cpu')\n",
        "\n",
        "category_dict = checkpoint['category_dict']\n",
        "subcategory_dict = checkpoint['subcategory_dict']\n",
        "word_dict = checkpoint['word_dict']\n",
        "\n",
        "dummy_embedding_matrix = np.zeros((len(word_dict) + 1, args.word_embedding_dim))\n",
        "model = NRMS(args, dummy_embedding_matrix)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "logging.info(f\"Model loaded from {ckpt_path}\")\n",
        "model.eval()\n",
        "news, news_index, category_dict, subcategory_dict, word_dict = read_news(\n",
        "  os.path.join(args.test_data_dir, 'news.tsv'), args.train_abstract_dir, args, mode='train')\n",
        "\n",
        "news_title, news_category, news_subcategory, news_abstract = get_doc_input(\n",
        "    news, news_index, category_dict, subcategory_dict, word_dict, args)\n",
        "\n",
        "news_combined = np.concatenate([x for x in [news_title, news_category, news_subcategory] if x is not None], axis=-1)\n",
        "\n",
        " \n",
        "news_dataset = NewsDataset(news_combined)\n",
        "news_dataloader = DataLoader(news_dataset,\n",
        "                                batch_size=args.batch_size,\n",
        "                                num_workers=4)\n",
        "\n",
        "news_scoring = []\n",
        "with torch.no_grad():\n",
        "    for input_ids in tqdm(news_dataloader):\n",
        "        input_ids = input_ids\n",
        "        news_vec = model.news_encoder(input_ids)\n",
        "        news_vec = news_vec.to(torch.device(\"cpu\")).detach().numpy()\n",
        "        news_scoring.extend(news_vec)\n",
        "\n",
        "news_scoring = np.array(news_scoring)\n",
        "logging.info(\"news scoring num: {}\".format(news_scoring.shape[0]))\n",
        "\n",
        "if rank == 0:\n",
        "    doc_sim = 0\n",
        "    for _ in tqdm(range(1000000)):\n",
        "        i = random.randrange(1, len(news_scoring))\n",
        "        j = random.randrange(1, len(news_scoring))\n",
        "        if i != j:\n",
        "            doc_sim += np.dot(news_scoring[i], news_scoring[j]) / (np.linalg.norm(news_scoring[i]) * np.linalg.norm(news_scoring[j]))\n",
        "    logging.info(f'News doc-sim: {doc_sim / 1000000}')\n",
        "\n",
        "data_file_path = os.path.join(args.test_data_dir, f'behaviors_{rank}.tsv')\n",
        "\n",
        "def collate_fn(tuple_list):\n",
        "    log_vecs = torch.FloatTensor([x[0] for x in tuple_list])\n",
        "    for i, x in enumerate(tuple_list):\n",
        "        print(f\"Sample {i}: candidate_news_feature shape = {x[2].shape}\")\n",
        "\n",
        "    log_mask = torch.FloatTensor([x[1] for x in tuple_list])\n",
        "    news_vecs = [x[2] for x in tuple_list]\n",
        "    labels = [x[3] for x in tuple_list]\n",
        "    return (log_vecs, log_mask, news_vecs, labels)\n",
        "\n",
        "dataset = DatasetTest(data_file_path, news_index, news_scoring, args)\n",
        "dataloader = DataLoader(dataset, batch_size=args.batch_size, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "um0H4NwW69yY"
      },
      "outputs": [],
      "source": [
        "args.mode = 'test'\n",
        "args.user_log_mask=True\n",
        "args.batch_size=128\n",
        "args.load_ckpt_name= 'epoch-5.pt'\n",
        "args.prepare=True\n",
        "if 'test' in args.mode:\n",
        "        if args.prepare:\n",
        "            logging.info('Preparing testing data...')\n",
        "            total_sample_num = prepare_testing_data(args.test_data_dir, args.nGPU)\n",
        "        else:\n",
        "            total_sample_num = 0\n",
        "            for i in range(args.nGPU):\n",
        "                data_file_path = os.path.join(args.test_data_dir, f'behaviors_{i}.tsv')\n",
        "                if not os.path.exists(data_file_path):\n",
        "                    logging.error(f'Splited testing data {data_file_path} for GPU {i} does not exist. Please set the parameter --prepare as True and rerun the code.')\n",
        "                    exit()\n",
        "                result = subprocess.getoutput(f'wc -l {data_file_path}')\n",
        "                total_sample_num += int(result.split(' ')[0])\n",
        "            logging.info('Skip testing data preparation.')\n",
        "        logging.info(f'{total_sample_num} testing samples in total.')\n",
        "\n",
        "        test(0, args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soI3jlXBCfD9"
      },
      "source": [
        "# Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abHIlnIvCgsI",
        "outputId": "3803e4e4-1391-4da6-d1c6-3d2d301823f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label = random.randint(0, 4)\n",
        "label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrDpWw36CiCe",
        "outputId": "69073a5d-0155-4f19-c263-b088af183c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-02-16 04:36:04--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2025-02-16 04:36:04--  https://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  4.99MB/s    in 6m 49s  \n",
            "\n",
            "2025-02-16 04:42:54 (5.07 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n",
            "Archive:  glove.840B.300d.zip\n",
            "  inflating: glove.840B.300d.txt     \n",
            "--2025-02-16 04:43:48--  https://mind201910small.blob.core.windows.net/release/MINDsmall_train.zip\n",
            "Resolving mind201910small.blob.core.windows.net (mind201910small.blob.core.windows.net)... 20.150.34.36\n",
            "Connecting to mind201910small.blob.core.windows.net (mind201910small.blob.core.windows.net)|20.150.34.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 409 Public access is not permitted on this storage account.\n",
            "2025-02-16 04:43:48 ERROR 409: Public access is not permitted on this storage account..\n",
            "\n",
            "--2025-02-16 04:43:48--  https://mind201910small.blob.core.windows.net/release/MINDsmall_dev.zip\n",
            "Resolving mind201910small.blob.core.windows.net (mind201910small.blob.core.windows.net)... 20.150.34.36\n",
            "Connecting to mind201910small.blob.core.windows.net (mind201910small.blob.core.windows.net)|20.150.34.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 409 Public access is not permitted on this storage account.\n",
            "2025-02-16 04:43:48 ERROR 409: Public access is not permitted on this storage account..\n",
            "\n",
            "unzip:  cannot find or open MINDsmall_train.zip, MINDsmall_train.zip.zip or MINDsmall_train.zip.ZIP.\n",
            "unzip:  cannot find or open MINDsmall_dev.zip, MINDsmall_dev.zip.zip or MINDsmall_dev.zip.ZIP.\n",
            "rm: cannot remove 'MINDsmall_train.zip': No such file or directory\n",
            "rm: cannot remove 'MINDsmall_dev.zip': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mkdir data\n",
        "!cd data\n",
        "\n",
        "# Dowload GloVe pre-trained word embedding and unzip\n",
        "!wget https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "!unzip glove.840B.300d.zip\n",
        "\n",
        "# Download MIND-small dataset and unzip\n",
        "!wget https://mind201910small.blob.core.windows.net/release/MINDsmall_train.zip\n",
        "!wget https://mind201910small.blob.core.windows.net/release/MINDsmall_dev.zip\n",
        "!unzip MINDsmall_train.zip -d MINDsmall_train\n",
        "!unzip MINDsmall_dev.zip -d MINDsmall_dev\n",
        "\n",
        "!rm glove.840B.300d.zip\n",
        "!rm MINDsmall_train.zip\n",
        "!rm MINDsmall_dev.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vU3UxmipCje4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
