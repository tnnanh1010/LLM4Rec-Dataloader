{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Recommenders contributors.\n",
    "# Licensed under the MIT License.\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "\n",
    "\n",
    "class ImplicitCF(object):\n",
    "    \"\"\"Data processing class for GCN models which use implicit feedback.\n",
    "\n",
    "    Initialize train and test set, create normalized adjacency matrix and sample data for training epochs.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train,\n",
    "        test=None,\n",
    "        adj_dir=None,\n",
    "        col_user='userID',\n",
    "        col_item='itemID',\n",
    "        col_rating='rating',\n",
    "        col_prediction='prediction',\n",
    "        seed=None,\n",
    "    ):\n",
    "        \"\"\"Constructor\n",
    "\n",
    "        Args:\n",
    "            adj_dir (str): Directory to save / load adjacency matrices. If it is None, adjacency\n",
    "                matrices will be created and will not be saved.\n",
    "            train (pandas.DataFrame): Training data with at least columns (col_user, col_item, col_rating).\n",
    "            test (pandas.DataFrame): Test data with at least columns (col_user, col_item, col_rating).\n",
    "                test can be None, if so, we only process the training data.\n",
    "            col_user (str): User column name.\n",
    "            col_item (str): Item column name.\n",
    "            col_rating (str): Rating column name.\n",
    "            seed (int): Seed.\n",
    "\n",
    "        \"\"\"\n",
    "        self.user_idx = None\n",
    "        self.item_idx = None\n",
    "        self.adj_dir = adj_dir\n",
    "        self.col_user = col_user\n",
    "        self.col_item = col_item\n",
    "        self.col_rating = col_rating\n",
    "        self.col_prediction = col_prediction\n",
    "        self.train, self.test = self._data_processing(train, test)\n",
    "        self._init_train_data()\n",
    "\n",
    "        random.seed(seed)\n",
    "\n",
    "    def _data_processing(self, train, test):\n",
    "        \"\"\"Process the dataset to reindex userID and itemID and only keep records with ratings greater than 0.\n",
    "\n",
    "        Args:\n",
    "            train (pandas.DataFrame): Training data with at least columns (col_user, col_item, col_rating).\n",
    "            test (pandas.DataFrame): Test data with at least columns (col_user, col_item, col_rating).\n",
    "                test can be None, if so, we only process the training data.\n",
    "\n",
    "        Returns:\n",
    "            list: train and test pandas.DataFrame Dataset, which have been reindexed and filtered.\n",
    "\n",
    "        \"\"\"\n",
    "        df = (\n",
    "            train\n",
    "            if test is None\n",
    "            else pd.concat([train, test], axis=0, ignore_index=True)\n",
    "        )\n",
    "\n",
    "        if self.user_idx is None:\n",
    "            user_idx = df[[self.col_user]].drop_duplicates().reindex()\n",
    "            user_idx[self.col_user + \"_idx\"] = np.arange(len(user_idx))\n",
    "            self.n_users = len(user_idx)\n",
    "            self.n_users_in_train = train[self.col_user].nunique()\n",
    "            self.user_idx = user_idx\n",
    "\n",
    "            self.user2id = dict(\n",
    "                zip(user_idx[self.col_user], user_idx[self.col_user + \"_idx\"])\n",
    "            )\n",
    "            self.id2user = dict(\n",
    "                zip(user_idx[self.col_user + \"_idx\"], user_idx[self.col_user])\n",
    "            )\n",
    "\n",
    "        if self.item_idx is None:\n",
    "            item_idx = df[[self.col_item]].drop_duplicates()\n",
    "            item_idx[self.col_item + \"_idx\"] = np.arange(len(item_idx))\n",
    "            self.n_items = len(item_idx)\n",
    "            self.item_idx = item_idx\n",
    "\n",
    "            self.item2id = dict(\n",
    "                zip(item_idx[self.col_item], item_idx[self.col_item + \"_idx\"])\n",
    "            )\n",
    "            self.id2item = dict(\n",
    "                zip(item_idx[self.col_item + \"_idx\"], item_idx[self.col_item])\n",
    "            )\n",
    "\n",
    "        return self._reindex(train), self._reindex(test)\n",
    "\n",
    "    def _reindex(self, df):\n",
    "        \"\"\"Process the dataset to reindex userID and itemID and only keep records with ratings greater than 0.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): dataframe with at least columns (col_user, col_item, col_rating).\n",
    "\n",
    "        Returns:\n",
    "            list: train and test pandas.DataFrame Dataset, which have been reindexed and filtered.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if df is None:\n",
    "            return None\n",
    "\n",
    "        df = pd.merge(df, self.user_idx, on=self.col_user, how=\"left\")\n",
    "        df = pd.merge(df, self.item_idx, on=self.col_item, how=\"left\")\n",
    "\n",
    "        df = df[df[self.col_rating] > 0]\n",
    "\n",
    "        df_reindex = df[\n",
    "            [self.col_user + \"_idx\", self.col_item + \"_idx\", self.col_rating]\n",
    "        ]\n",
    "        df_reindex.columns = [self.col_user, self.col_item, self.col_rating]\n",
    "\n",
    "        return df_reindex\n",
    "\n",
    "    def _init_train_data(self):\n",
    "        \"\"\"Record items interated with each user in a dataframe self.interact_status, and create adjacency\n",
    "        matrix self.R.\n",
    "\n",
    "        \"\"\"\n",
    "        self.interact_status = (\n",
    "            self.train.groupby(self.col_user)[self.col_item]\n",
    "            .apply(set)\n",
    "            .reset_index()\n",
    "            .rename(columns={self.col_item: self.col_item + \"_interacted\"})\n",
    "        )\n",
    "        self.R = sp.dok_matrix((self.n_users, self.n_items), dtype=np.float32)\n",
    "        self.R[self.train[self.col_user], self.train[self.col_item]] = 1.0\n",
    "\n",
    "    def get_norm_adj_mat(self):\n",
    "        \"\"\"Load normalized adjacency matrix if it exists, otherwise create (and save) it.\n",
    "\n",
    "        Returns:\n",
    "            scipy.sparse.csr_matrix: Normalized adjacency matrix.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if self.adj_dir is None:\n",
    "                raise FileNotFoundError\n",
    "            norm_adj_mat = sp.load_npz(self.adj_dir + \"/norm_adj_mat.npz\")\n",
    "            print(\"Already load norm adj matrix.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            norm_adj_mat = self.create_norm_adj_mat()\n",
    "            if self.adj_dir is not None:\n",
    "                sp.save_npz(self.adj_dir + \"/norm_adj_mat.npz\", norm_adj_mat)\n",
    "        return norm_adj_mat\n",
    "\n",
    "    def create_norm_adj_mat(self):\n",
    "        \"\"\"Create normalized adjacency matrix.\n",
    "\n",
    "        Returns:\n",
    "            scipy.sparse.csr_matrix: Normalized adjacency matrix.\n",
    "\n",
    "        \"\"\"\n",
    "        adj_mat = sp.dok_matrix(\n",
    "            (self.n_users + self.n_items, self.n_users + self.n_items), dtype=np.float32\n",
    "        )\n",
    "        adj_mat = adj_mat.tolil()\n",
    "        R = self.R.tolil()\n",
    "\n",
    "        adj_mat[: self.n_users, self.n_users :] = R\n",
    "        adj_mat[self.n_users :, : self.n_users] = R.T\n",
    "        adj_mat = adj_mat.todok()\n",
    "        print(\"Already create adjacency matrix.\")\n",
    "\n",
    "        rowsum = np.array(adj_mat.sum(1))\n",
    "        d_inv = np.power(rowsum + 1e-9, -0.5).flatten()\n",
    "        d_inv[np.isinf(d_inv)] = 0.0\n",
    "        d_mat_inv = sp.diags(d_inv)\n",
    "        norm_adj_mat = d_mat_inv.dot(adj_mat)\n",
    "        norm_adj_mat = norm_adj_mat.dot(d_mat_inv)\n",
    "        print(\"Already normalize adjacency matrix.\")\n",
    "\n",
    "        return norm_adj_mat.tocsr()\n",
    "\n",
    "    def train_loader(self, batch_size):\n",
    "        \"\"\"Sample train data every batch. One positive item and one negative item sampled for each user.\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): Batch size of users.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray, numpy.ndarray, numpy.ndarray:\n",
    "            - Sampled users.\n",
    "            - Sampled positive items.\n",
    "            - Sampled negative items.\n",
    "        \"\"\"\n",
    "\n",
    "        def sample_neg(x):\n",
    "            if len(x) >= self.n_items:\n",
    "                raise ValueError(\"A user has voted in every item. Can't find a negative sample.\")\n",
    "            while True:\n",
    "                neg_id = random.randint(0, self.n_items - 1)\n",
    "                if neg_id not in x:\n",
    "                    return neg_id\n",
    "\n",
    "        indices = range(self.n_users_in_train)\n",
    "        if self.n_users < batch_size:\n",
    "            users = [random.choice(indices) for _ in range(batch_size)]\n",
    "        else:\n",
    "            users = random.sample(indices, batch_size)\n",
    "\n",
    "        interact = self.interact_status.iloc[users]\n",
    "        pos_items = interact[self.col_item + \"_interacted\"].apply(\n",
    "            lambda x: random.choice(list(x))\n",
    "        )\n",
    "        neg_items = interact[self.col_item + \"_interacted\"].apply(\n",
    "            lambda x: sample_neg(x)\n",
    "        )\n",
    "\n",
    "        return np.array(users), np.array(pos_items), np.array(neg_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphLoader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msplitter\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmovielens\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgraphLoader\u001b[39;00m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphLoader'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import splitter\n",
    "import movielens\n",
    "import graphLoader # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinmike/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "split = splitter.random_split(movielens.load_pandas_df(\"100K\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImplicitCF(train=split[0], test=split[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>296</td>\n",
       "      <td>281</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>627</td>\n",
       "      <td>352</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>294</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106</td>\n",
       "      <td>451</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>725</td>\n",
       "      <td>492</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>222</td>\n",
       "      <td>73</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>300</td>\n",
       "      <td>132</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>2</td>\n",
       "      <td>856</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>75</td>\n",
       "      <td>179</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>510</td>\n",
       "      <td>66</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userID  itemID  rating\n",
       "0         296     281     5.0\n",
       "1         627     352     3.0\n",
       "2         255     294     5.0\n",
       "3         106     451     5.0\n",
       "4         725     492     1.0\n",
       "...       ...     ...     ...\n",
       "19995     222      73     3.0\n",
       "19996     300     132     3.0\n",
       "19997       2     856     5.0\n",
       "19998      75     179     5.0\n",
       "19999     510      66     2.0\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
